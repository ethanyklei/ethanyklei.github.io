<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>EthanLei</title>
    <link>https://ethanyklei.github.io/zh-cn/</link>
    <description>Recent content on EthanLei</description>
    <image>
      <title>EthanLei</title>
      <url>https://ethanyklei.github.io/images/papermod-cover.png</url>
      <link>https://ethanyklei.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.139.3</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 02 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ethanyklei.github.io/zh-cn/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lossè®¡ç®—æŠ€å·§ä¹‹Logsumexp</title>
      <link>https://ethanyklei.github.io/zh-cn/blogs/posts/loss%E8%AE%A1%E7%AE%97%E6%8A%80%E5%B7%A7%E4%B9%8Blogsumexp/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://ethanyklei.github.io/zh-cn/blogs/posts/loss%E8%AE%A1%E7%AE%97%E6%8A%80%E5%B7%A7%E4%B9%8Blogsumexp/</guid>
      <description>Desc Text.</description>
    </item>
    <item>
      <title>Policy-gradient Algorithem</title>
      <link>https://ethanyklei.github.io/zh-cn/blogs/posts/policy_gradient_algorithem/</link>
      <pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://ethanyklei.github.io/zh-cn/blogs/posts/policy_gradient_algorithem/</guid>
      <description>Desc Text.</description>
    </item>
    <item>
      <title>About Me</title>
      <link>https://ethanyklei.github.io/zh-cn/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ethanyklei.github.io/zh-cn/about/</guid>
      <description>&lt;p&gt;Helloï¼æˆ‘å«é›·æ˜“é”Ÿï¼ˆEthan Leiï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥å«æˆ‘ Kunkunï¼Œæ˜¯ä¸ªè·Ÿç€æ„Ÿè§‰æ´»ç€çš„äººï¼ˆä½†æ˜¯ä¹ŸåŒæ ·éœ€è¦ğŸ¥–å’ŒğŸºï¼‰ã€‚
ç›®å‰ï¼Œæˆ‘æ˜¯å°çº¢ä¹¦ç¤¾åŒºæœç´¢çš„ä¸€åç®—æ³•å·¥ç¨‹å¸ˆï¼Œä¸»è¦åœ¨å‚ä¸ç”Ÿæˆå¼æœç´¢ç›¸å…³çš„ä¸šåŠ¡ã€‚
2017ï½2021å¹´ï¼Œæˆ‘åœ¨ä¸œåŒ—å¤§å­¦æ”»è¯»å­¦å£«å­¦ä½ã€‚éšåï¼Œ2021ï½2024å¹´ï¼Œæˆ‘åœ¨å¤©æ´¥å¤§å­¦&lt;a href=&#34;https://tjunlp-lab.github.io/&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤&lt;/a&gt;ï¼ˆTJUNLPï¼‰&lt;a href=&#34;https://dyxiong.github.io/&#34;&gt;ç†Šå¾·æ„&lt;/a&gt;æ•™æˆçš„æŒ‡å¯¼ä¸‹ï¼Œè·å¾—äº†ç¡•å£«å­¦ä½ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘çš„ç ”ç©¶å…´è¶£ä¸»è¦é›†ä¸­åœ¨ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸŒŸâ€ƒ&lt;strong&gt;æœºå™¨ç¿»è¯‘&lt;/strong&gt;ï¼š åŒ…æ‹¬äº†ç¯‡ç« çº§ç¥ç»æœºå™¨ç¿»è¯‘ã€è¯­éŸ³ç¿»è¯‘å’Œå›¾åƒç¿»è¯‘ã€‚&lt;/li&gt;
&lt;li&gt;ğŸŒŸâ€ƒ&lt;strong&gt;LLM-based Agent&lt;/strong&gt;ï¼šç‰¹åˆ«æ˜¯å¤§æ¨¡å‹çš„Reasoningèƒ½åŠ›å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›çš„ç ”ç©¶ã€‚&lt;/li&gt;
&lt;li&gt;ğŸŒŸâ€ƒ&lt;strong&gt;AIåŸç”Ÿåº”ç”¨&lt;/strong&gt;ï¼šç›®å‰ä¸»è¦ä¸“æ³¨åœ¨AIæœç´¢æ–¹å‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘è¿˜å¾ˆå–œæ¬¢ï¼š
- ğŸ“·&amp;emsp;**æ‘„å½±**ï¼šè·Ÿç€æ„Ÿè§‰æ´»çš„äººï¼Œå¾ˆéš¾ä¸å–œæ¬¢æ‘„å½±ã€‚
- ğŸ‘œ&amp;emsp;**æ—…è¡Œ**ï¼šä»å°åœ°ç†å°±å­¦çš„ä¸å¥½ï¼Œå¹¶ä¸æ˜¯å› ä¸ºä¸å–œæ¬¢ï¼Œè€Œæ˜¯å¯¹æ–‡å­—æè¿°çš„ä¸–ç•Œä¸æ•æ„Ÿã€‚
- ğŸ•º&amp;emsp;**è·³èˆ**ï¼šHiphopäººï¼ŒHiphopé­‚ã€‚ --&gt;
&lt;!-- ## News
- ğŸ”¥ [2024-6] æˆ‘ä»¬çš„ç”Ÿæˆå¼AIæœç´¢äº§å“ **&lt;font color=&#34;red&#34; &gt;æœæœè–¯&lt;/font&gt;** å·²ç»å…¥é©»å°çº¢ä¹¦æœç´¢ï¼Œå¿«å»æœç´¢æ¡†æŠ“ä»–å§ï½
- ğŸ”¥ [2024-6] æˆ‘ä»¬çš„å¯¹è¯å¼AIäº§å“ [**&lt;font color=&#34;red&#34; &gt;è¾¾èŠ¬å¥‡&lt;/font&gt;**](https://www.xiaohongshu.com/user/profile/65b896ce000000000d01dc75) å‡ºé“å•¦ï¼å¿«å»æ‰¾ä»–èŠå¤©ï¼ --&gt;
&lt;h2 id=&#34;ç»å†&#34;&gt;ç»å†&lt;/h2&gt;
&lt;!-- - ğŸ§‘â€ğŸ’»&amp;emsp;2023.11 ~ Now&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;: ç®—æ³•å·¥ç¨‹å¸ˆ, å°çº¢ä¹¦. ä¸»è¦è´Ÿè´£æ­å»ºLLM-based Agentç³»ç»Ÿå’Œç”Ÿæˆå¼AIæœç´¢ç³»ç»Ÿã€‚
- ğŸ§‘â€ğŸ’»&amp;emsp;2023.08~2023.11: å®ä¹ ç”Ÿ, åºæ˜åŸºé‡‘. ä¸»è¦è´Ÿè´£ç«¯åˆ°ç«¯ä¸­é«˜é¢‘å› å­æŒ–æ˜ç›¸å…³å·¥ä½œ.
- ğŸ§‘â€ğŸ’»&amp;emsp;2022.09~2023.08: å®ä¹ ç”Ÿ, Oppoç ”ç©¶é™¢. ä¸»è¦è´Ÿè´£ç«¯åˆ°ç«¯è¯­éŸ³ç¿»è¯‘å’ŒåŸºäºå¤§æ¨¡å‹çš„æœºå™¨ç¿»è¯‘ç›¸å…³ç ”ç©¶.
- ğŸ§‘â€ğŸ“&amp;emsp;2021.09~2022.09: ç ”ç©¶ç”Ÿ, å¤©æ´¥å¤§å­¦. ä¸»è¦ä»äº‹ç¯‡ç« çº§ç¥ç»æœºå™¨ç¿»è¯‘ç›¸å…³ç ”ç©¶.
- ğŸ§‘â€ğŸ“&amp;emsp;2019.09~2020.01: äº¤æ¢ç”Ÿ, åŒ—æµ·é“å¤§å­¦. æƒ…æŠ¥å·¥ç¨‹ä¸“ä¸š. 
- ğŸ§‘â€ğŸ“&amp;emsp;2017.09~2021.09: æœ¬ç§‘ç”Ÿ, ä¸œåŒ—å¤§å­¦. è½¯ä»¶å·¥ç¨‹ä¸“ä¸š.  --&gt;
&lt;div class=&#34;timeline&#34;&gt;
  
    &lt;div class=&#34;timeline-item&#34;&gt;
      &lt;div class=&#34;timeline-left&#34;&gt;
        &lt;div class=&#34;timeline-date&#34;&gt;2023.11 ~ Now&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&#34;timeline-right&#34;&gt;
        &lt;div class=&#34;timeline-title&#34;&gt;å°çº¢ä¹¦&lt;/div&gt;
        &lt;div class=&#34;timeline-position&#34;&gt;ğŸ§‘â€ğŸ’» ç®—æ³•å·¥ç¨‹å¸ˆ&lt;/div&gt;
        &lt;div class=&#34;timeline-description&#34;&gt;ä¸»è¦è´Ÿè´£æ­å»ºLLM-based Agentç³»ç»Ÿå’Œç”Ÿæˆå¼AIæœç´¢ç³»ç»Ÿã€‚&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  
    &lt;div class=&#34;timeline-item&#34;&gt;
      &lt;div class=&#34;timeline-left&#34;&gt;
        &lt;div class=&#34;timeline-date&#34;&gt;2023.08 ~ 2023.11&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&#34;timeline-right&#34;&gt;
        &lt;div class=&#34;timeline-title&#34;&gt;åºæ˜åŸºé‡‘&lt;/div&gt;
        &lt;div class=&#34;timeline-position&#34;&gt;ğŸ§‘â€ğŸ’» å®ä¹ ç”Ÿ&lt;/div&gt;
        &lt;div class=&#34;timeline-description&#34;&gt;ä¸»è¦è´Ÿè´£ç«¯åˆ°ç«¯ä¸­é«˜é¢‘å› å­æŒ–æ˜ç›¸å…³å·¥ä½œã€‚&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  
    &lt;div class=&#34;timeline-item&#34;&gt;
      &lt;div class=&#34;timeline-left&#34;&gt;
        &lt;div class=&#34;timeline-date&#34;&gt;2022.09 ~ 2023.08&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&#34;timeline-right&#34;&gt;
        &lt;div class=&#34;timeline-title&#34;&gt;Oppoç ”ç©¶é™¢&lt;/div&gt;
        &lt;div class=&#34;timeline-position&#34;&gt;ğŸ§‘â€ğŸ’» å®ä¹ ç”Ÿ&lt;/div&gt;
        &lt;div class=&#34;timeline-description&#34;&gt;ä¸»è¦è´Ÿè´£ç«¯åˆ°ç«¯è¯­éŸ³ç¿»è¯‘å’ŒåŸºäºå¤§æ¨¡å‹çš„æœºå™¨ç¿»è¯‘ç›¸å…³ç ”ç©¶ã€‚&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  
    &lt;div class=&#34;timeline-item&#34;&gt;
      &lt;div class=&#34;timeline-left&#34;&gt;
        &lt;div class=&#34;timeline-date&#34;&gt;2021.09 ~ 2024.03&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&#34;timeline-right&#34;&gt;
        &lt;div class=&#34;timeline-title&#34;&gt;å¤©æ´¥å¤§å­¦&lt;/div&gt;
        &lt;div class=&#34;timeline-position&#34;&gt;ğŸ§‘â€ğŸ“ ç ”ç©¶ç”Ÿ&lt;/div&gt;
        &lt;div class=&#34;timeline-description&#34;&gt;ä¸»è¦ä»äº‹ç¯‡ç« çº§ç¥ç»æœºå™¨ç¿»è¯‘ç›¸å…³ç ”ç©¶ã€‚&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  
    &lt;div class=&#34;timeline-item&#34;&gt;
      &lt;div class=&#34;timeline-left&#34;&gt;
        &lt;div class=&#34;timeline-date&#34;&gt;2019.09 ~ 2020.01&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&#34;timeline-right&#34;&gt;
        &lt;div class=&#34;timeline-title&#34;&gt;åŒ—æµ·é“å¤§å­¦&lt;/div&gt;
        &lt;div class=&#34;timeline-position&#34;&gt;ğŸ§‘â€ğŸ“ äº¤æ¢ç”Ÿ&lt;/div&gt;
        &lt;div class=&#34;timeline-description&#34;&gt;æƒ…æŠ¥å·¥ç¨‹ä¸“ä¸š&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  
    &lt;div class=&#34;timeline-item&#34;&gt;
      &lt;div class=&#34;timeline-left&#34;&gt;
        &lt;div class=&#34;timeline-date&#34;&gt;2017.09 ~ 2021.09&lt;/div&gt;
      &lt;/div&gt;
      &lt;div class=&#34;timeline-right&#34;&gt;
        &lt;div class=&#34;timeline-title&#34;&gt;ä¸œåŒ—å¤§å­¦&lt;/div&gt;
        &lt;div class=&#34;timeline-position&#34;&gt;ğŸ§‘â€ğŸ“ æœ¬ç§‘ç”Ÿ&lt;/div&gt;
        &lt;div class=&#34;timeline-description&#34;&gt;è½¯ä»¶å·¥ç¨‹ä¸“ä¸š&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  
&lt;/div&gt;

&lt;!-- ## Publications [[google scholar]](https://scholar.google.com/citations?user=mxpXRBYAAAAJ&amp;hl=zh-CN)
### 2024
- ğŸ“„&amp;emsp;Meizhi Zhong, Xikai Liu, Chen Zhang, **Yikun Lei**, Yan Gao, Yao Hu, Kehai Chen and Min Zhang. [ZigZagKV: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty](). COLING(2025)
- ğŸ“„&amp;emsp;Meizhi Zhong, Chen Zhang, **Yikun Lei**, Xikai Liu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang. [Understanding the RoPE Extensions of Long-Context LLMs: An Attention Perspective
](https://arxiv.org/abs/2406.13282). COLING(2025).
- ğŸ“„&amp;emsp;Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, **Yikun Lei**, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong. [FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data](https://arxiv.org/abs/2408.06273). ArXiv(2024).
- ğŸ“„&amp;emsp;Hao Wang, Zhengshan Xue, **Yikun Lei**, Deyi Xiong. [End-to-End Speech Translation with Mutual Knowledge Distillation](https://ieeexplore.ieee.org/abstract/document/10445811/). ICASSP (2024).
- ğŸ“„&amp;emsp;Xiaohu Zhao, Haoran Sun, **Yikun Lei**, Deyi Xiong. [Regularizing Cross-Attention Learning for End-to-End Speech Translation with ASR and MT Attention Matrices](https://www.sciencedirect.com/science/article/abs/pii/S0957417424001064). Expert Systems with Applications.
### 2023
- ğŸ“„&amp;emsp;**Yikun Lei**, Zhengshan Xue, Xiaohu Zhao, Haoran Sun, Shaolin Zhu, Xiaodong Lin, Deyi Xiong. [CKDST: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation](https://aclanthology.org/2023.findings-acl.195.pdf). ACL Findings(2023).
- ğŸ“„&amp;emsp;Shaolin Zhu, Shangjie Li, **Yikun Lei**, Deyi Xiong. [PEIT: Bridging the Modality Gap with Pre-trained Models for End-to-End Image Translation](https://aclanthology.org/2023.acl-long.751.pdf). ACL(2023).
- ğŸ“„&amp;emsp;Haoran Sun, Xiaohu Zhao, **Yikun Lei**, Shaolin Zhu, Deyi Xiong. [Towards a Deep Understanding of Multilingual End-to-End Speech Translation](https://arxiv.org/pdf/2310.20456). EMNLP Findings(2023).
- ğŸ“„&amp;emsp;Xiaohu Zhao, Haoran Sun, **Yikun Lei**, Shaolin Zhu, Deyi Xiong. [CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation](https://aclanthology.org/2023.findings-emnlp.394.pdf). EMNLP Findings(2023).
### 2022
- ğŸ“„&amp;emsp;**Yikun Lei**, Yuqi Ren, Deyi Xiong. [CoDoNMT: Modeling Cohesion Devices for Document-Level Neural Machine Translation](https://aclanthology.org/2022.coling-1.462.pdf). COLING(2022).
- ğŸ“„&amp;emsp;Haoran Sun, **Yikun Lei**, Deyi Xiong. [Multilingual Neural Machine Transliteration with Adaptive Segmentation Schemes](https://ieeexplore.ieee.org/abstract/document/9961282). IALP(2022).

 --&gt;</description>
    </item>
    <item>
      <title>Publications</title>
      <link>https://ethanyklei.github.io/zh-cn/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ethanyklei.github.io/zh-cn/publications/</guid>
      <description>&lt;h2 id=&#34;2024&#34;&gt;2024&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„â€ƒMeizhi Zhong, Xikai Liu, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yan Gao, Yao Hu, Kehai Chen and Min Zhang. &lt;a href=&#34;https://ethanyklei.github.io/zh-cn/&#34;&gt;ZigZagKV: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty&lt;/a&gt;. COLING(2025)&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒMeizhi Zhong, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Xikai Liu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang. &lt;a href=&#34;https://arxiv.org/abs/2406.13282&#34;&gt;Understanding the RoPE Extensions of Long-Context LLMs: An Attention Perspective
&lt;/a&gt;. COLING(2025).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHaoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/abs/2408.06273&#34;&gt;FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data&lt;/a&gt;. ArXiv(2024).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHao Wang, Zhengshan Xue, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/10445811/&#34;&gt;End-to-End Speech Translation with Mutual Knowledge Distillation&lt;/a&gt;. ICASSP (2024).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒXiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0957417424001064&#34;&gt;Regularizing Cross-Attention Learning for End-to-End Speech Translation with ASR and MT Attention Matrices&lt;/a&gt;. Expert Systems with Applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2023&#34;&gt;2023&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„â€ƒ&lt;strong&gt;Yikun Lei&lt;/strong&gt;, Zhengshan Xue, Xiaohu Zhao, Haoran Sun, Shaolin Zhu, Xiaodong Lin, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-acl.195.pdf&#34;&gt;CKDST: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation&lt;/a&gt;. ACL Findings(2023).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒShaolin Zhu, Shangjie Li, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.acl-long.751.pdf&#34;&gt;PEIT: Bridging the Modality Gap with Pre-trained Models for End-to-End Image Translation&lt;/a&gt;. ACL(2023).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHaoran Sun, Xiaohu Zhao, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/pdf/2310.20456&#34;&gt;Towards a Deep Understanding of Multilingual End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒXiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-emnlp.394.pdf&#34;&gt;CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2022&#34;&gt;2022&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„â€ƒ&lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yuqi Ren, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2022.coling-1.462.pdf&#34;&gt;CoDoNMT: Modeling Cohesion Devices for Document-Level Neural Machine Translation&lt;/a&gt;. COLING(2022).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHaoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9961282&#34;&gt;Multilingual Neural Machine Transliteration with Adaptive Segmentation Schemes&lt;/a&gt;. IALP(2022).&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
