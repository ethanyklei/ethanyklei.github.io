<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>EthanLei</title>
    <link>http://localhost:1313/en/</link>
    <description>Recent content on EthanLei</description>
    <image>
      <title>EthanLei</title>
      <url>http://localhost:1313/images/papermod-cover.png</url>
      <link>http://localhost:1313/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.139.3</generator>
    <language>en</language>
    <lastBuildDate>Mon, 21 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/en/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Policy-gradient Algorithem</title>
      <link>http://localhost:1313/en/blogs/posts/policy_gradient_algorithem/</link>
      <pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/en/blogs/posts/policy_gradient_algorithem/</guid>
      <description>Desc Text.</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/en/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/en/about/</guid>
      <description>&lt;p&gt;Hello! I&amp;rsquo;m Ethan Lei (é›·æ˜“é”Ÿ), but feel free to call me Kunkun. I&amp;rsquo;m an idealist at heart who believes in the transformative power of technology.
Currently, I&amp;rsquo;m working as an Algorithm Engineer at Xiaohongshu Inc., where I focus on developing AI-powered search products and pioneering AI-native applications.
My academic journey includes a Bachelor&amp;rsquo;s degree from Northeastern University (2017-2021) and a Master&amp;rsquo;s degree from Tianjin University (2021-2023), where I was fortunate to work with &lt;a href=&#34;https://tjunlp-lab.github.io/&#34;&gt;TJUNLP&lt;/a&gt; under the guidance of &lt;a href=&#34;https://dyxiong.github.io/&#34;&gt;Prof. Deiyi Xiong&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Publications</title>
      <link>http://localhost:1313/en/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/en/publications/</guid>
      <description>&lt;h2 id=&#34;2024&#34;&gt;2024&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ðŸ“„â€ƒMeizhi Zhong, Xikai Liu, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yan Gao, Yao Hu, Kehai Chen and Min Zhang. &lt;a href=&#34;http://localhost:1313/en/&#34;&gt;ZigZagKV: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty&lt;/a&gt;. COLING(2025)&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒMeizhi Zhong, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Xikai Liu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang. &lt;a href=&#34;https://arxiv.org/abs/2406.13282&#34;&gt;Understanding the RoPE Extensions of Long-Context LLMs: An Attention Perspective
&lt;/a&gt;. COLING(2025).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒHaoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/abs/2408.06273&#34;&gt;FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data&lt;/a&gt;. ArXiv(2024).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒHao Wang, Zhengshan Xue, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/10445811/&#34;&gt;End-to-End Speech Translation with Mutual Knowledge Distillation&lt;/a&gt;. ICASSP (2024).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒXiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0957417424001064&#34;&gt;Regularizing Cross-Attention Learning for End-to-End Speech Translation with ASR and MT Attention Matrices&lt;/a&gt;. Expert Systems with Applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2023&#34;&gt;2023&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ðŸ“„â€ƒ&lt;strong&gt;Yikun Lei&lt;/strong&gt;, Zhengshan Xue, Xiaohu Zhao, Haoran Sun, Shaolin Zhu, Xiaodong Lin, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-acl.195.pdf&#34;&gt;CKDST: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation&lt;/a&gt;. ACL Findings(2023).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒShaolin Zhu, Shangjie Li, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.acl-long.751.pdf&#34;&gt;PEIT: Bridging the Modality Gap with Pre-trained Models for End-to-End Image Translation&lt;/a&gt;. ACL(2023).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒHaoran Sun, Xiaohu Zhao, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/pdf/2310.20456&#34;&gt;Towards a Deep Understanding of Multilingual End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒXiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-emnlp.394.pdf&#34;&gt;CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2022&#34;&gt;2022&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ðŸ“„â€ƒ&lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yuqi Ren, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2022.coling-1.462.pdf&#34;&gt;CoDoNMT: Modeling Cohesion Devices for Document-Level Neural Machine Translation&lt;/a&gt;. COLING(2022).&lt;/li&gt;
&lt;li&gt;ðŸ“„â€ƒHaoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9961282&#34;&gt;Multilingual Neural Machine Transliteration with Adaptive Segmentation Schemes&lt;/a&gt;. IALP(2022).&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
