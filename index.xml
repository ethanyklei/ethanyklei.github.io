<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>EthanLei</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on EthanLei</description>
    <image>
      <title>EthanLei</title>
      <url>http://localhost:1313/images/papermod-cover.png</url>
      <link>http://localhost:1313/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.139.3</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 30 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Helloï¼æˆ‘å«é›·æ˜“é”Ÿï¼ˆEthan Leiï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥å«æˆ‘ Kunkunï¼Œæ˜¯ä¸ªè·Ÿç€æ„Ÿè§‰æ´»ç€çš„äººï¼ˆä½†æ˜¯ä¹ŸåŒæ ·éœ€è¦ğŸ¥–å’ŒğŸºï¼‰ã€‚
ç›®å‰ï¼Œæˆ‘æ˜¯å°çº¢ä¹¦ç¤¾åŒºæœç´¢çš„ä¸€åç®—æ³•å·¥ç¨‹å¸ˆï¼Œä¸»è¦åœ¨å‚ä¸ç”Ÿæˆå¼æœç´¢ç›¸å…³çš„ä¸šåŠ¡ã€‚
2017ï½2021å¹´ï¼Œæˆ‘åœ¨ä¸œåŒ—å¤§å­¦æ”»è¯»å­¦å£«å­¦ä½ã€‚éšåï¼Œ2021ï½2024å¹´ï¼Œæˆ‘åœ¨å¤©æ´¥å¤§å­¦&lt;a href=&#34;https://tjunlp-lab.github.io/&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤&lt;/a&gt;ï¼ˆTJUNLPï¼‰&lt;a href=&#34;https://dyxiong.github.io/&#34;&gt;ç†Šå¾·æ„&lt;/a&gt;æ•™æˆçš„æŒ‡å¯¼ä¸‹ï¼Œè·å¾—äº†ç¡•å£«å­¦ä½ã€‚&lt;/p&gt;
&lt;p&gt;æˆ‘çš„ç ”ç©¶å…´è¶£ä¸»è¦é›†ä¸­åœ¨ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸŒŸâ€ƒ&lt;strong&gt;æœºå™¨ç¿»è¯‘&lt;/strong&gt;ï¼š åŒ…æ‹¬äº†ç¯‡ç« çº§ç¥ç»æœºå™¨ç¿»è¯‘ã€è¯­éŸ³ç¿»è¯‘å’Œå›¾åƒç¿»è¯‘ã€‚&lt;/li&gt;
&lt;li&gt;ğŸŒŸâ€ƒ&lt;strong&gt;LLM-based Agent&lt;/strong&gt;ï¼šç‰¹åˆ«æ˜¯å¤§æ¨¡å‹æœ¬èº«Reasoningèƒ½åŠ›å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›çš„ç ”ç©¶ã€‚&lt;/li&gt;
&lt;li&gt;ğŸŒŸâ€ƒ&lt;strong&gt;AIåŸç”Ÿåº”ç”¨&lt;/strong&gt;ï¼šç›®å‰ä¸»è¦ä¸“æ³¨åœ¨AIæœç´¢æ–¹å‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘è¿˜å¾ˆå–œæ¬¢ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“·â€ƒ&lt;strong&gt;æ‘„å½±&lt;/strong&gt;ï¼šè·Ÿç€æ„Ÿè§‰æ´»çš„äººï¼Œå¾ˆéš¾ä¸å–œæ¬¢æ‘„å½±ã€‚&lt;/li&gt;
&lt;li&gt;ğŸ‘œâ€ƒ&lt;strong&gt;æ—…è¡Œ&lt;/strong&gt;ï¼šä»å°åœ°ç†å°±å­¦çš„ä¸å¥½ï¼Œå¹¶ä¸æ˜¯å› ä¸ºä¸å–œæ¬¢ï¼Œè€Œæ˜¯å¯¹æ–‡å­—æè¿°çš„ä¸–ç•Œä¸æ•æ„Ÿã€‚&lt;/li&gt;
&lt;li&gt;ğŸ•ºâ€ƒ&lt;strong&gt;è·³èˆ&lt;/strong&gt;ï¼šHiphopäººï¼ŒHiphopé­‚ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ç»å†&#34;&gt;ç»å†&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ§‘â€ğŸ’»â€ƒ2023.11 ~ NowÂ Â Â Â Â : ç®—æ³•å·¥ç¨‹å¸ˆ, å°çº¢ä¹¦. ä¸»è¦è´Ÿè´£æ­å»ºLLM-based Agentç³»ç»Ÿå’Œç”Ÿæˆå¼AIæœç´¢ç³»ç»Ÿã€‚&lt;/li&gt;
&lt;li&gt;ğŸ§‘â€ğŸ’»â€ƒ2023.08~2023.11: å®ä¹ ç”Ÿ, åºæ˜åŸºé‡‘. ä¸»è¦è´Ÿè´£ç«¯åˆ°ç«¯ä¸­é«˜é¢‘å› å­æŒ–æ˜ç›¸å…³å·¥ä½œ.&lt;/li&gt;
&lt;li&gt;ğŸ§‘â€ğŸ’»â€ƒ2022.09~2023.08: å®ä¹ ç”Ÿ, Oppoç ”ç©¶é™¢. ä¸»è¦è´Ÿè´£ç«¯åˆ°ç«¯è¯­éŸ³ç¿»è¯‘å’ŒåŸºäºå¤§æ¨¡å‹çš„æœºå™¨ç¿»è¯‘ç›¸å…³ç ”ç©¶.&lt;/li&gt;
&lt;li&gt;ğŸ§‘â€ğŸ“â€ƒ2021.09~2022.09: ç ”ç©¶ç”Ÿ, å¤©æ´¥å¤§å­¦. ä¸»è¦ä»äº‹ç¯‡ç« çº§ç¥ç»æœºå™¨ç¿»è¯‘ç›¸å…³ç ”ç©¶.&lt;/li&gt;
&lt;li&gt;ğŸ§‘â€ğŸ“â€ƒ2019.09~2020.01: äº¤æ¢ç”Ÿ, åŒ—æµ·é“å¤§å­¦. æƒ…æŠ¥å·¥ç¨‹ä¸“ä¸š.&lt;/li&gt;
&lt;li&gt;ğŸ§‘â€ğŸ“â€ƒ2017.09~2021.09: æœ¬ç§‘ç”Ÿ, ä¸œåŒ—å¤§å­¦. è½¯ä»¶å·¥ç¨‹ä¸“ä¸š.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;publications-google-scholarhttpsscholargooglecomcitationsusermxpxrbyaaaajhlzh-cn&#34;&gt;Publications &lt;a href=&#34;https://scholar.google.com/citations?user=mxpXRBYAAAAJ&amp;hl=zh-CN&#34;&gt;[google scholar]&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&#34;2024&#34;&gt;2024&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„â€ƒMeizhi Zhong, Xikai Liu, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yan Gao, Yao Hu, Kehai Chen and Min Zhang. &lt;a href=&#34;http://localhost:1313/&#34;&gt;ZigZagKV: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty&lt;/a&gt;. COLING(2025)&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒMeizhi Zhong, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Xikai Liu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang. &lt;a href=&#34;https://arxiv.org/abs/2406.13282&#34;&gt;Understanding the RoPE Extensions of Long-Context LLMs: An Attention Perspective
&lt;/a&gt;. COLING(2025).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHaoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/abs/2408.06273&#34;&gt;FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data&lt;/a&gt;. ArXiv(2024).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHao Wang, Zhengshan Xue, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/10445811/&#34;&gt;End-to-End Speech Translation with Mutual Knowledge Distillation&lt;/a&gt;. ICASSP (2024).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒXiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0957417424001064&#34;&gt;Regularizing Cross-Attention Learning for End-to-End Speech Translation with ASR and MT Attention Matrices&lt;/a&gt;. Expert Systems with Applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2023&#34;&gt;2023&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„â€ƒ&lt;strong&gt;Yikun Lei&lt;/strong&gt;, Zhengshan Xue, Xiaohu Zhao, Haoran Sun, Shaolin Zhu, Xiaodong Lin, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-acl.195.pdf&#34;&gt;CKDST: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation&lt;/a&gt;. ACL Findings(2023).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒShaolin Zhu, Shangjie Li, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.acl-long.751.pdf&#34;&gt;PEIT: Bridging the Modality Gap with Pre-trained Models for End-to-End Image Translation&lt;/a&gt;. ACL(2023).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHaoran Sun, Xiaohu Zhao, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/pdf/2310.20456&#34;&gt;Towards a Deep Understanding of Multilingual End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒXiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-emnlp.394.pdf&#34;&gt;CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2022&#34;&gt;2022&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ğŸ“„â€ƒ&lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yuqi Ren, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2022.coling-1.462.pdf&#34;&gt;CoDoNMT: Modeling Cohesion Devices for Document-Level Neural Machine Translation&lt;/a&gt;. COLING(2022).&lt;/li&gt;
&lt;li&gt;ğŸ“„â€ƒHaoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9961282&#34;&gt;Multilingual Neural Machine Transliteration with Adaptive Segmentation Schemes&lt;/a&gt;. IALP(2022).&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Policy-gradient Algorithem</title>
      <link>http://localhost:1313/blogs/posts/policy_gradient_algorithem/</link>
      <pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blogs/posts/policy_gradient_algorithem/</guid>
      <description>Desc Text.</description>
    </item>
  </channel>
</rss>
