<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>EthanLei</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on EthanLei</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 30 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Sat, 30 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;p&gt;Hello！我叫雷易锟（Ethan Lei），你也可以叫我 Kunkun，是个跟着感觉活着的人（但是也同样需要🥖和🍺）。&#xA;目前，我是小红书社区搜索的一名算法工程师，主要在参与生成式搜索相关的业务。&#xA;2017～2021年，我在东北大学攻读学士学位。随后，2021～2024年，我在天津大学&lt;a href=&#34;https://tjunlp-lab.github.io/&#34;&gt;自然语言处理实验室&lt;/a&gt;（TJUNLP）&lt;a href=&#34;https://dyxiong.github.io/&#34;&gt;熊德意&lt;/a&gt;教授的指导下，获得了硕士学位。&lt;/p&gt;&#xA;&lt;p&gt;我的研究兴趣主要集中在：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🌟 &lt;strong&gt;机器翻译&lt;/strong&gt;： 包括了篇章级神经机器翻译、语音翻译和图像翻译。&lt;/li&gt;&#xA;&lt;li&gt;🌟 &lt;strong&gt;LLM-based Agent&lt;/strong&gt;：特别是大模型本身Reasoning能力和工具使用能力的研究。&lt;/li&gt;&#xA;&lt;li&gt;🌟 &lt;strong&gt;AI原生应用&lt;/strong&gt;：目前主要专注在AI搜索方向。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;除此之外，我还很喜欢：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📷 &lt;strong&gt;摄影&lt;/strong&gt;：跟着感觉活的人，很难不喜欢摄影。&lt;/li&gt;&#xA;&lt;li&gt;👜 &lt;strong&gt;旅行&lt;/strong&gt;：从小地理就学的不好，并不是因为不喜欢，而是对文字描述的世界不敏感。&lt;/li&gt;&#xA;&lt;li&gt;🕺 &lt;strong&gt;跳舞&lt;/strong&gt;：Hiphop人，Hiphop魂。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;经历&#34;&gt;经历&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🧑‍💻 2023.11 ~ Now     : 算法工程师, 小红书. 主要负责搭建LLM-based Agent系统和生成式AI搜索系统。&lt;/li&gt;&#xA;&lt;li&gt;🧑‍💻 2023.08~2023.11: 实习生, 序明基金. 主要负责端到端中高频因子挖掘相关工作.&lt;/li&gt;&#xA;&lt;li&gt;🧑‍💻 2022.09~2023.08: 实习生, Oppo研究院. 主要负责端到端语音翻译和基于大模型的机器翻译相关研究.&lt;/li&gt;&#xA;&lt;li&gt;🧑‍🎓 2021.09~2022.09: 研究生, 天津大学. 主要从事篇章级神经机器翻译相关研究.&lt;/li&gt;&#xA;&lt;li&gt;🧑‍🎓 2019.09~2020.01: 交换生, 北海道大学. 情报工程专业.&lt;/li&gt;&#xA;&lt;li&gt;🧑‍🎓 2017.09~2021.09: 本科生, 东北大学. 软件工程专业.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;publications-google-scholarhttpsscholargooglecomcitationsusermxpxrbyaaaajhlzh-cn&#34;&gt;Publications &lt;a href=&#34;https://scholar.google.com/citations?user=mxpXRBYAAAAJ&amp;hl=zh-CN&#34;&gt;[google scholar]&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;2024&#34;&gt;2024&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📄 Meizhi Zhong, Xikai Liu, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yan Gao, Yao Hu, Kehai Chen and Min Zhang. &lt;a href=&#34;http://localhost:1313/&#34;&gt;ZigZagKV: Dynamic KV Cache Compression for Long-context Modeling based on Layer Uncertainty&lt;/a&gt;. COLING(2025)&lt;/li&gt;&#xA;&lt;li&gt;📄 Meizhi Zhong, Chen Zhang, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Xikai Liu, Yan Gao, Yao Hu, Kehai Chen, Min Zhang. &lt;a href=&#34;https://arxiv.org/abs/2406.13282&#34;&gt;Understanding the RoPE Extensions of Long-Context LLMs: An Attention Perspective&#xA;&lt;/a&gt;. COLING(2025).&lt;/li&gt;&#xA;&lt;li&gt;📄 Haoran Sun, Renren Jin, Shaoyang Xu, Leiyu Pan, Supryadi, Menglong Cui, Jiangcun Du, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Lei Yang, Ling Shi, Juesi Xiao, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/abs/2408.06273&#34;&gt;FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data&lt;/a&gt;. ArXiv(2024).&lt;/li&gt;&#xA;&lt;li&gt;📄 Hao Wang, Zhengshan Xue, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/10445811/&#34;&gt;End-to-End Speech Translation with Mutual Knowledge Distillation&lt;/a&gt;. ICASSP (2024).&lt;/li&gt;&#xA;&lt;li&gt;📄 Xiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0957417424001064&#34;&gt;Regularizing Cross-Attention Learning for End-to-End Speech Translation with ASR and MT Attention Matrices&lt;/a&gt;. Expert Systems with Applications.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2023&#34;&gt;2023&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📄 &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Zhengshan Xue, Xiaohu Zhao, Haoran Sun, Shaolin Zhu, Xiaodong Lin, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-acl.195.pdf&#34;&gt;CKDST: Comprehensively and Effectively Distill Knowledge from Machine Translation to End-to-End Speech Translation&lt;/a&gt;. ACL Findings(2023).&lt;/li&gt;&#xA;&lt;li&gt;📄 Shaolin Zhu, Shangjie Li, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.acl-long.751.pdf&#34;&gt;PEIT: Bridging the Modality Gap with Pre-trained Models for End-to-End Image Translation&lt;/a&gt;. ACL(2023).&lt;/li&gt;&#xA;&lt;li&gt;📄 Haoran Sun, Xiaohu Zhao, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://arxiv.org/pdf/2310.20456&#34;&gt;Towards a Deep Understanding of Multilingual End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;&#xA;&lt;li&gt;📄 Xiaohu Zhao, Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Shaolin Zhu, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2023.findings-emnlp.394.pdf&#34;&gt;CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation&lt;/a&gt;. EMNLP Findings(2023).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2022&#34;&gt;2022&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📄 &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Yuqi Ren, Deyi Xiong. &lt;a href=&#34;https://aclanthology.org/2022.coling-1.462.pdf&#34;&gt;CoDoNMT: Modeling Cohesion Devices for Document-Level Neural Machine Translation&lt;/a&gt;. COLING(2022).&lt;/li&gt;&#xA;&lt;li&gt;📄 Haoran Sun, &lt;strong&gt;Yikun Lei&lt;/strong&gt;, Deyi Xiong. &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9961282&#34;&gt;Multilingual Neural Machine Transliteration with Adaptive Segmentation Schemes&lt;/a&gt;. IALP(2022).&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Policy-gradient Algorithem</title>
      <link>http://localhost:1313/blogs/posts/policy_gradient_algorithem/</link>
      <pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blogs/posts/policy_gradient_algorithem/</guid>
      <description>&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;&#xA;&lt;p&gt;Policy-gradient 算法是无模型强化学习算法中的一种，也是Actor-Critic 算法中的Actor。&#xA;REINFORCE算法是一个比较基础的&lt;/p&gt;&#xA;&lt;h2 id=&#34;算法&#34;&gt;算法&lt;/h2&gt;&#xA;&lt;h3 id=&#34;学习目标&#34;&gt;学习目标&lt;/h3&gt;&#xA;&lt;p&gt;Policy-gradient 的目标函数定义如下：&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;\begin{equation}&#xA;J(\theta)=\mathbb{E}[\sum_{t=0}^{T-1}r_{t+1}]&#xA;\end{equation}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;它表示希望学习一个policy能够最大化累计未来回报（cumulative future reward）。&#xA;$r_{t+1}$表示在状态 $s_t$时采取动作 $a_t$从环境中获得的回报。 $r_{t+1} = R(s_t,a_t)$， $R(\cdot)$表示回报函数（reward function）&#xA;因为这是个最大化问题，所以可以使用梯度上升来优化policy。&#xA;$$&#xA;\begin{equation}&#xA;\theta = \theta + \frac{\delta}{\delta \theta}J(\theta)&#xA;\end{equation}&#xA;$$&#xA;Policy 一般会使用神经网络进行参数化。&lt;/p&gt;&#xA;&lt;h3 id=&#34;期望expection&#34;&gt;期望（Expection）&lt;/h3&gt;&#xA;&lt;p&gt;在文献中经常出现的是期望符号——之所以使用它，是因为我们想要优化长期未来（预测的）奖励，而这有一定的不确定性。&#xA;期望值，也称为期望值或平均值，是通过每个x值及其概率的乘积之和来计算的。&#xA;$$&#xA;\begin{equation}&#xA;\mathbb{E}[f(x)] = \sum_{x}P(x)f(x)&#xA;\end{equation}&#xA;$$&#xA;$P(x)$代表随机变量 $x$出现的概率， $f(x)$代表 $x$的值。&lt;/p&gt;&#xA;&lt;h3 id=&#34;推导策略梯度&#34;&gt;推导策略梯度&lt;/h3&gt;&#xA;&lt;p&gt;我们根据先前定义的目标函数，我们可以将期望项进行展开：&#xA;$$&#xA;\begin{equation}&#xA;\begin{split}&#xA;J(\theta) &amp;amp;= \mathbb{E}[\sum_{t=0}^{T-1}r_{t+1}|\pi_{\theta}] \\&#xA;&amp;amp;= \sum_{t=i}^{T-1} P(s_t,a_t|\tau)r_{t+1}&#xA;\end{split}&#xA;\end{equation}&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;其中 $i$是轨迹 $\tau$中的任意一个起始点， $P(s_t,a_t|\tau)$是在给定轨迹 $\tau$时，出现 $s_t,a_t$的概率。&#xA;对两边同时对policy的参数 $\theta$求导：&#xA;$$&#xA;\begin{equation}&#xA;\begin{split}&#xA;\nabla_{\theta}J(\theta) &amp;amp;= \sum_{t=i}^{T-1}\nabla_{\theta}P(s_t,a_t|\tau)r_{t+1} \\&#xA;&amp;amp;=\sum_{t=i}^{T-1}P(s_t,a_t|\tau)\frac{\nabla_{\theta}P(s_t,a_t|\tau)}{P(s_t,a_t|\tau)} r_{t+1} \\&#xA;&amp;amp;=\sum_{t=i}^{T-1}P(s_t,a_t|\tau)\nabla_{\theta}\log{P(s_t,a_t|\tau)}r_{t+1} \\&#xA;&amp;amp; = \mathbb{E}[\sum_{t=i}^{T-1}\nabla_{\theta}\log{P(s_t,a_t|\tau)r_{t+1}}]&#xA;\end{split}&#xA;\end{equation}&#xA;$$&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
